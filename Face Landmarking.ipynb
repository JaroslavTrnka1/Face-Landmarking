{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import urllib.request as urlreq\n",
    "import os\n",
    "from pylab import rcParams\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtps(input):\n",
    "    \"\"\"\n",
    "    Function to read a .TPS file\n",
    "    Args:\n",
    "        input (str): path to the .TPS file\n",
    "    Returns:\n",
    "        lm (str list): info extracted from 'LM=' field\n",
    "        im (str list): info extracted from 'IMAGE=' field\n",
    "        id (str list): info extracted from 'ID=' filed\n",
    "        coords: returns a 3D numpy array if all the individuals have same\n",
    "                number of landmarks, otherwise returns a list containing 2d\n",
    "                matrices of landmarks\n",
    "    \"\"\"\n",
    "\n",
    "    # open the file\n",
    "    tps_file = open(input, 'r')  # 'r' = read\n",
    "    tps = tps_file.read().splitlines()  # read as lines and split by new lines\n",
    "    tps_file.close()\n",
    "\n",
    "    # initiate lists to take fields of \"LM=\",\"IMAGE=\", \"ID=\" and the coords\n",
    "    lm, im, ID, coords_array = [], [], [], []\n",
    "\n",
    "    # looping thru the lines\n",
    "    for i, ln in enumerate(tps):\n",
    "\n",
    "        # Each individual starts with \"LM=\"\n",
    "        if ln.startswith(\"LM\"):\n",
    "            # number of landmarks of this ind\n",
    "            lm_num = int(ln.split('=')[1])\n",
    "            # fill the info to the list for all inds\n",
    "            lm.append(lm_num)\n",
    "            # initiate a list to take 2d coordinates\n",
    "            coords_mat = []\n",
    "\n",
    "            # fill the coords list by reading next lm_num of lines\n",
    "            for j in range(i + 1, i + 1 + lm_num):\n",
    "                coords_mat.append(tps[j].split(' '))  # split lines into values\n",
    "\n",
    "            # change the list into a numpy matrix storing float vals\n",
    "            coords_mat = np.array(coords_mat, dtype=float)\n",
    "            # fill the ind 2d matrix into the 3D coords array of all inds\n",
    "            coords_array.append(coords_mat)\n",
    "            # coords_array.append(coords_mat)\n",
    "\n",
    "        # Get info of IMAGE= and ID= fields\n",
    "        if ln.startswith(\"IMAGE\"):\n",
    "            im.append(ln.split('=')[1])\n",
    "\n",
    "        if ln.startswith(\"ID\"):\n",
    "            ID.append(ln.split('=')[1])\n",
    "\n",
    "    # check if all inds contains same number of landmarks\n",
    "    all_lm_same = all(x == lm[0] for x in lm)\n",
    "    # if all same change the list into a 3d numpy array\n",
    "    if all_lm_same:\n",
    "        coords_array = np.dstack(coords_array)\n",
    "\n",
    "    # return results in dictionary form\n",
    "    return {'lm': lm, 'im': im, 'id': ID, 'coords': coords_array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LBF_model(image, prepared = False):\n",
    "    if not prepared:\n",
    "        # save face detection algorithm's name as haarcascade\n",
    "        haarcascade = \"haarcascade_frontalface_alt2.xml\"\n",
    "\n",
    "        # save facial landmark detection model's name as LBFmodel\n",
    "        LBFmodel = \"lbfmodel.yaml\"\n",
    "\n",
    "        if (haarcascade not in os.listdir(os.curdir)):\n",
    "            haarcascade_url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt2.xml\"\n",
    "            urlreq.urlretrieve(haarcascade_url, haarcascade)\n",
    "\n",
    "        if (LBFmodel not in os.listdir(os.curdir)):\n",
    "            LBFmodel_url = \"https://github.com/kurnianggoro/GSOC2017/raw/master/data/lbfmodel.yaml\"\n",
    "            urlreq.urlretrieve(LBFmodel_url, LBFmodel)\n",
    "\n",
    "        # create an instance of the Face Detection Cascade Classifier\n",
    "        detector = cv2.CascadeClassifier(haarcascade)\n",
    "        # create an instance of the Facial landmark Detector with the model\n",
    "        landmark_detector = cv2.face.createFacemarkLBF()\n",
    "        landmark_detector.loadModel(LBFmodel)\n",
    "    \n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Detect faces using the haarcascade classifier on the \"grayscale image\"\n",
    "    faces = detector.detectMultiScale(image_gray)\n",
    "\n",
    "    # Detect landmarks on \"image_gray\"\n",
    "    _, landmarks = landmark_detector.fit(image_gray, faces)\n",
    "    landmarks = landmarks[0][0,:,:]\n",
    "    landmarks = np.divide(landmarks, (image.shape[1], image.shape[0]))\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MediaPipe_model(image):\n",
    "    landmarks = np.empty((478, 2))\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=True,\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,    # Zpřesnění kolem očí a pusy!!\n",
    "        min_detection_confidence=0.5) as face_mesh:\n",
    "\n",
    "        # To improve performance\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Detect the face landmarks\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # To improve performance\n",
    "        #image.flags.writeable = True\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for i, l_mark in enumerate(face_landmarks.landmark):\n",
    "                landmarks[i,:] = l_mark.x, l_mark.y\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_landmarks(landmarks, img, pixel_scale = False):\n",
    "    x_coor = landmarks[:,0]\n",
    "    y_coor = landmarks[:,1]\n",
    "    if not pixel_scale:\n",
    "        x_coor = np.multiply(x_coor, img.shape[1])\n",
    "        y_coor = np.multiply(y_coor, img.shape[0])\n",
    "        \n",
    "    fig, ax = plt.subplots(1, figsize = (10,10))\n",
    "    ax.imshow(image)\n",
    "    #ax.axis('off')\n",
    "\n",
    "    for x, y in zip(x_coor, y_coor):\n",
    "        circ = Circle((x,y), 2, color='white', fill = False)\n",
    "        ax.add_patch(circ)  \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pixel analysis - hair edge\n",
    "def hair_edge(image, middle_landmarks):\n",
    "    forehead = image[0:min(middle_landmarks[:,1]), middle_landmarks[0,0]:middle_landmarks[1,0],:]\n",
    "\n",
    "    kmeans = KMeans(n_clusters = 3, n_init = 10).fit(forehead.reshape(-1,3))\n",
    "    forehead_labels = kmeans.labels_.reshape(forehead.shape[0], forehead.shape[1])\n",
    "    background_label = kmeans.cluster_centers_.mean(axis = 1).argmax()\n",
    "    non_background_label = kmeans.cluster_centers_.mean(axis = 1).argmin()\n",
    "    \n",
    "    Y_coordinate = np.array([range(forehead.shape[0])] * forehead.shape[1]).transpose()\n",
    "    forehead_labels = forehead_labels.reshape(-1,1)\n",
    "    Y_coordinate = Y_coordinate.reshape(-1,1)\n",
    "    \n",
    "    face_pixels_idx = (forehead_labels != background_label).nonzero()[0]\n",
    "    Y = Y_coordinate[face_pixels_idx]\n",
    "    labels = (forehead_labels[face_pixels_idx] == non_background_label).reshape(-1,)\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(Y, labels)\n",
    "    decision_boundary = -log_reg.intercept_/log_reg.coef_\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    plt.plot(np.arange(image.shape[1]),np.array([decision_boundary] * image.shape[1]).reshape(-1,))\n",
    "    plt.show()\n",
    "    return decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Pipeline\n",
    "\n",
    "def prepare_training_landmarks(both_models = True):\n",
    "    if both_models:\n",
    "        x = np.empty((0, 546 * 2))\n",
    "    else:\n",
    "        x = np.empty((0, 478 * 2))\n",
    "    y_true = np.empty((0, 144))\n",
    "    \n",
    "    # some tree structure here\n",
    "    groups = ['Males', 'Females']\n",
    "    path = 'C:\\\\Users\\\\Zirov\\\\landmarks\\\\'\n",
    "    \n",
    "    for group in groups:\n",
    "        tps = readtps(path + group + '.TPS')\n",
    "        \n",
    "        for idx in range(len(tps['im'])):\n",
    "            print(f'Group: {group}, index: {idx}', end = '\\r')\n",
    "            true_landmarks = tps['coords'][:, :, idx]\n",
    "            img_path = path + group + '\\\\' + tps['im'][idx]\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            true_landmarks = np.divide(true_landmarks, (image.shape[1], image.shape[0]))\n",
    "\n",
    "            # Both model use float(0,1) for x and y axis\n",
    "            if both_models:\n",
    "                input_landmarks = np.concatenate((LBF_model(image), MediaPipe_model(image)), axis = 0)\n",
    "            else:\n",
    "                input_landmarks = MediaPipe_model(image)\n",
    "                \n",
    "            # batch_dim = 0\n",
    "            input_landmarks = input_landmarks.reshape(1,-1)\n",
    "            x = np.concatenate((x, input_landmarks), axis = 0)\n",
    "            true_landmarks = true_landmarks.reshape(1,-1)\n",
    "            y_true = np.concatenate((y_true, true_landmarks), axis = 0)\n",
    "    return x, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Females, index: 143\r"
     ]
    }
   ],
   "source": [
    "x,y = prepare_training_landmarks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 1092)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 144)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
